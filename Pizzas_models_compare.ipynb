{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGoiU5D5M0Ay",
        "outputId": "692e6380-c231-452d-9adb-2c402fa8daa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCreating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Ultralytics: 8.4.9\n"
          ]
        }
      ],
      "source": [
        "!pip -q install -U ultralytics\n",
        "\n",
        "import os\n",
        "import time\n",
        "import yaml\n",
        "import math\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from ultralytics import YOLO\n",
        "\n",
        "print(\"Ultralytics:\", __import__(\"ultralytics\").__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -U \"kaggle==1.8.2\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5hBD9TSX9Kq",
        "outputId": "e087dffd-4629-411a-f86b-9cae1ad92b9e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.9/88.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m256.4/256.4 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m131.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m160.4/160.4 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m192.4/192.4 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.2/55.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m269.8/269.8 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json\n",
        "from pathlib import Path\n",
        "\n",
        "kaggle_dir = Path.home() / \".kaggle\"\n",
        "kaggle_dir.mkdir(parents=True, exist_ok=True)\n",
        "dst = kaggle_dir / \"kaggle.json\"\n",
        "\n",
        "sources = [Path(\"/content/kaggle.json\"), Path(\"./kaggle.json\")]\n",
        "src = next((p for p in sources if p.exists()), None)\n",
        "if src is None:\n",
        "    raise FileNotFoundError(\"kaggle.json not found. Place it at ./kaggle.json or /content/kaggle.json\")\n",
        "\n",
        "dst.write_text(src.read_text(), encoding=\"utf-8\")\n",
        "os.chmod(dst, 0o600)\n",
        "\n",
        "creds = json.loads(dst.read_text(encoding=\"utf-8\"))\n",
        "os.environ[\"KAGGLE_USERNAME\"] = creds[\"username\"]\n",
        "os.environ[\"KAGGLE_KEY\"] = creds[\"key\"]\n",
        "\n",
        "print(\"Configured:\", dst)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pki_9JocYBqb",
        "outputId": "43706b83-178d-4265-f9d3-1b8697d5ee1d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configured: /root/.kaggle/kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "out_dir = Path(\"./pizza_toppings_od\")\n",
        "DATA_ROOT = out_dir\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "!kaggle datasets download -d matthiasbartolo/pizza-toppings-object-detection -p {str(out_dir)} --unzip\n",
        "print(\"Downloaded to:\", out_dir.resolve())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfdXT6UsYCpk",
        "outputId": "83e3d9cc-5bdb-47f3-c6f8-171ba5583d4c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/matthiasbartolo/pizza-toppings-object-detection\n",
            "License(s): MIT\n",
            "Downloading pizza-toppings-object-detection.zip to pizza_toppings_od\n",
            "100% 1.10G/1.10G [00:09<00:00, 119MB/s]\n",
            "100% 1.10G/1.10G [00:09<00:00, 126MB/s]\n",
            "Downloaded to: /content/pizza_toppings_od\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PIZZA_SRC_ID = 14\n",
        "\n",
        "OUT_ROOT = Path(\"./pizza_only_dataset\").resolve()\n",
        "\n",
        "IMGSZ = 640\n",
        "BATCH = 16\n",
        "DEVICE = 0\n",
        "HALF = True\n",
        "EPOCHS = 30\n",
        "PATIENCE = 10\n",
        "\n",
        "MODEL_CANDIDATES = [\n",
        "    \"yolo26s.pt\", \"yolo11s.pt\",\"yolov8s.pt\"\n",
        "]\n",
        "\n",
        "WEIGHTS = {\n",
        "    \"recall\": 0.35,\n",
        "    \"precision\": 0.20,\n",
        "    \"ap50\": 0.25,\n",
        "    \"fps\": 0.20,\n",
        "}\n"
      ],
      "metadata": {
        "id": "19UtCYH8M5c8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_ROOT = Path(\"pizza_toppings_od/Pizza Object Detector.v7i.yolov8\").resolve()\n",
        "\n",
        "assert DATASET_ROOT.exists(), f\"Not found: {DATASET_ROOT}\"\n",
        "\n",
        "print(DATASET_ROOT)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnXtbfUOZgaZ",
        "outputId": "519d48d7-a7cc-4283-8e6a-b03bbf3c9a4f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pizza_toppings_od/Pizza Object Detector.v7i.yolov8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pick_val_name(root: Path):\n",
        "    if (root / \"valid\").exists():\n",
        "        return \"valid\"\n",
        "    if (root / \"val\").exists():\n",
        "        return \"val\"\n",
        "    raise FileNotFoundError(\"Neither 'valid' nor 'val' folder exists\")\n",
        "\n",
        "VAL_NAME = pick_val_name(DATASET_ROOT)\n",
        "\n",
        "SPLITS = {\n",
        "    \"train\": DATASET_ROOT / \"train\",\n",
        "    \"val\": DATASET_ROOT / VAL_NAME,\n",
        "    \"test\": DATASET_ROOT / \"test\",\n",
        "}\n",
        "\n",
        "for s, p in SPLITS.items():\n",
        "    assert (p / \"images\").exists(), f\"Missing: {p/'images'}\"\n",
        "    assert (p / \"labels\").exists(), f\"Missing: {p/'labels'}\"\n",
        "\n",
        "print(\"Using splits:\", {k: str(v) for k, v in SPLITS.items()})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bcn515cQOd_1",
        "outputId": "2d6f0714-2957-44da-e82b-7ebcd023b989"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using splits: {'train': '/content/pizza_toppings_od/Pizza Object Detector.v7i.yolov8/train', 'val': '/content/pizza_toppings_od/Pizza Object Detector.v7i.yolov8/valid', 'test': '/content/pizza_toppings_od/Pizza Object Detector.v7i.yolov8/test'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ensure_empty_dir(p: Path):\n",
        "    if p.exists():\n",
        "        shutil.rmtree(p)\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "ensure_empty_dir(OUT_ROOT)\n",
        "\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    (OUT_ROOT / split / \"images\").mkdir(parents=True, exist_ok=True)\n",
        "    (OUT_ROOT / split / \"labels\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def convert_label_file(src_lbl: Path, dst_lbl: Path, pizza_src_id: int) -> bool:\n",
        "    \"\"\"\n",
        "    Read YOLO label file lines: class x y w h\n",
        "    Keep only class==pizza_src_id and remap to class 0.\n",
        "    Returns True if at least one pizza box exists.\n",
        "    \"\"\"\n",
        "    if not src_lbl.exists():\n",
        "        return False\n",
        "\n",
        "    kept = []\n",
        "    for line in src_lbl.read_text(encoding=\"utf-8\").splitlines():\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        parts = line.split()\n",
        "        if len(parts) < 5:\n",
        "            continue\n",
        "        cls = int(float(parts[0]))\n",
        "        if cls == pizza_src_id:\n",
        "            parts[0] = \"0\"\n",
        "            kept.append(\" \".join(parts[:5]))\n",
        "\n",
        "    if kept:\n",
        "        dst_lbl.write_text(\"\\n\".join(kept) + \"\\n\", encoding=\"utf-8\")\n",
        "        return True\n",
        "    else:\n",
        "        if dst_lbl.exists():\n",
        "            dst_lbl.unlink()\n",
        "        return False\n",
        "\n",
        "stats = []\n",
        "for split, split_dir in SPLITS.items():\n",
        "    img_dir = split_dir / \"images\"\n",
        "    lbl_dir = split_dir / \"labels\"\n",
        "\n",
        "    imgs = []\n",
        "    for ext in (\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.bmp\",\"*.webp\"):\n",
        "        imgs += list(img_dir.glob(ext))\n",
        "    imgs = sorted(imgs)\n",
        "\n",
        "    kept_imgs = 0\n",
        "    kept_boxes = 0\n",
        "    total_imgs = len(imgs)\n",
        "\n",
        "    for img_path in imgs:\n",
        "        lbl_path = lbl_dir / (img_path.stem + \".txt\")\n",
        "        out_img = OUT_ROOT / split / \"images\" / img_path.name\n",
        "        out_lbl = OUT_ROOT / split / \"labels\" / (img_path.stem + \".txt\")\n",
        "\n",
        "        has_pizza = convert_label_file(lbl_path, out_lbl, PIZZA_SRC_ID)\n",
        "        if has_pizza:\n",
        "            shutil.copy2(img_path, out_img)\n",
        "            kept_imgs += 1\n",
        "            kept_boxes += len(out_lbl.read_text().splitlines())\n",
        "\n",
        "    stats.append({\"split\": split, \"total_imgs\": total_imgs, \"pizza_imgs\": kept_imgs, \"pizza_boxes\": kept_boxes})\n",
        "\n",
        "pd.DataFrame(stats)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "GFypYTPSSRZK",
        "outputId": "2e0f6684-c357-4ba6-f807-ea78e77b43cd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   split  total_imgs  pizza_imgs  pizza_boxes\n",
              "0  train        2540        2522         2686\n",
              "1    val         284         279          292\n",
              "2   test         283         281          313"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-33771e6e-068f-4570-8fc1-bbfb2702b72e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>split</th>\n",
              "      <th>total_imgs</th>\n",
              "      <th>pizza_imgs</th>\n",
              "      <th>pizza_boxes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train</td>\n",
              "      <td>2540</td>\n",
              "      <td>2522</td>\n",
              "      <td>2686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>val</td>\n",
              "      <td>284</td>\n",
              "      <td>279</td>\n",
              "      <td>292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test</td>\n",
              "      <td>283</td>\n",
              "      <td>281</td>\n",
              "      <td>313</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33771e6e-068f-4570-8fc1-bbfb2702b72e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-33771e6e-068f-4570-8fc1-bbfb2702b72e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-33771e6e-068f-4570-8fc1-bbfb2702b72e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"split\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"train\",\n          \"val\",\n          \"test\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_imgs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1302,\n        \"min\": 283,\n        \"max\": 2540,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2540,\n          284,\n          283\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pizza_imgs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1294,\n        \"min\": 279,\n        \"max\": 2522,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2522,\n          279,\n          281\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pizza_boxes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1376,\n        \"min\": 292,\n        \"max\": 2686,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2686,\n          292,\n          313\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pizza_yaml = {\n",
        "    \"path\": str(OUT_ROOT),\n",
        "    \"train\": \"train/images\",\n",
        "    \"val\": \"val/images\",\n",
        "    \"test\": \"test/images\",\n",
        "    \"nc\": 1,\n",
        "    \"names\": [\"pizza\"],\n",
        "}\n",
        "\n",
        "PIZZA_YAML = Path(\"./pizza_only.yaml\").resolve()\n",
        "PIZZA_YAML.write_text(yaml.safe_dump(pizza_yaml, sort_keys=False), encoding=\"utf-8\")\n",
        "\n",
        "print(\"Wrote:\", PIZZA_YAML)\n",
        "print(pizza_yaml)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rexmd5j5S96d",
        "outputId": "b207b482-6be9-4a4e-fad7-931b51e36cd3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote: /content/pizza_only.yaml\n",
            "{'path': '/content/pizza_only_dataset', 'train': 'train/images', 'val': 'val/images', 'test': 'test/images', 'nc': 1, 'names': ['pizza']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_series(s: pd.Series) -> pd.Series:\n",
        "    s = s.astype(float)\n",
        "    if s.isna().all():\n",
        "        return pd.Series([0.0] * len(s), index=s.index)\n",
        "    vmin, vmax = np.nanmin(s.values), np.nanmax(s.values)\n",
        "    if math.isclose(vmin, vmax):\n",
        "        return pd.Series([0.0] * len(s), index=s.index)\n",
        "    return (s - vmin) / (vmax - vmin)\n",
        "\n",
        "rows = []\n",
        "\n",
        "for w in MODEL_CANDIDATES:\n",
        "    print(f\"\\n==============================\")\n",
        "    print(f\"TRAIN (1-class pizza): {w}\")\n",
        "    print(f\"==============================\")\n",
        "\n",
        "    model = YOLO(w)\n",
        "\n",
        "    train_res = model.train(\n",
        "        data=str(PIZZA_YAML),\n",
        "        imgsz=IMGSZ,\n",
        "        batch=BATCH,\n",
        "        device=DEVICE,\n",
        "        epochs=EPOCHS,\n",
        "        patience=PATIENCE,\n",
        "        pretrained=True,\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    best_pt = Path(train_res.save_dir) / \"weights\" / \"best.pt\"\n",
        "    if not best_pt.exists():\n",
        "        raise FileNotFoundError(f\"best.pt not found at {best_pt}\")\n",
        "\n",
        "    print(f\"\\nTEST EVAL: {best_pt}\")\n",
        "    model_ft = YOLO(str(best_pt))\n",
        "\n",
        "    res = model_ft.val(\n",
        "        data=str(PIZZA_YAML),\n",
        "        split=\"test\",\n",
        "        imgsz=IMGSZ,\n",
        "        batch=BATCH,\n",
        "        device=DEVICE,\n",
        "        half=HALF,\n",
        "        verbose=False,\n",
        "        plots=False\n",
        "    )\n",
        "\n",
        "    precision = float(res.box.mp)\n",
        "    recall    = float(res.box.mr)\n",
        "    ap50      = float(res.box.map50)\n",
        "    ap5095    = float(res.box.map)\n",
        "\n",
        "    speed = getattr(res, \"speed\", {}) or {}\n",
        "    inf_ms = float(speed.get(\"inference\", np.nan))\n",
        "    fps = (1000.0 / inf_ms) if (inf_ms and inf_ms > 0) else np.nan\n",
        "\n",
        "    rows.append({\n",
        "        \"base_model\": w,\n",
        "        \"best_weights\": str(best_pt),\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"ap50\": ap50,\n",
        "        \"ap5095\": ap5095,\n",
        "        \"inf_ms/img\": inf_ms,\n",
        "        \"fps_est\": fps,\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FzxJpFvmTcsa",
        "outputId": "85f90efd-ec86-4195-ad52-b2339a480226"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============================\n",
            "TRAIN (1-class pizza): yolo26s.pt\n",
            "==============================\n",
            "Ultralytics 8.4.9 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/pizza_only.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo26s.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 24.1MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
            "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5, 3, True]        \n",
            " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    477184  ultralytics.nn.modules.block.C3k2            [768, 256, 1, True]           \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1    136192  ultralytics.nn.modules.block.C3k2            [512, 128, 1, True]           \n",
            " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1   1843712  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True, 0.5, True]\n",
            " 23        [16, 19, 22]  1    932638  ultralytics.nn.modules.head.Detect           [1, 1, True, [128, 256, 512]] \n",
            "YOLO26s summary: 260 layers, 9,948,638 parameters, 9,948,638 gradients, 22.5 GFLOPs\n",
            "\n",
            "Transferred 696/708 items from pretrained weights\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n.pt to 'yolo26n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.3MB 91.6MB/s 0.1s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3145.2Â±1415.8 MB/s, size: 168.2 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/pizza_only_dataset/train/labels... 2522 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2522/2522 2.4Kit/s 1.1s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/pizza_only_dataset/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1062.4Â±1028.5 MB/s, size: 200.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/pizza_only_dataset/val/labels... 279 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 279/279 1.3Kit/s 0.2s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/pizza_only_dataset/val/labels.cache\n",
            "Plotting labels to /content/runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 114 weight(decay=0.0), 126 weight(decay=0.0005), 126 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/train\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/30      4.81G     0.7557      1.111    0.02041         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 1.9it/s 1:25\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.7s/it 14.9s\n",
            "                   all        279        292      0.801       0.77      0.869      0.612\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/30      5.64G     0.8356     0.4445    0.02284         30        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.4it/s 1:05\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.4it/s 3.7s\n",
            "                   all        279        292      0.925      0.924       0.97      0.733\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/30      5.68G     0.8187     0.4085    0.02186         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.5it/s 1:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.1it/s 2.9s\n",
            "                   all        279        292      0.756      0.783      0.801      0.591\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/30      5.74G     0.7957     0.4294    0.02109         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.5it/s 1:03\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.1it/s 2.9s\n",
            "                   all        279        292      0.947      0.923      0.974      0.802\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/30      5.77G     0.7113     0.3505    0.01852         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.5it/s 1:03\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.1it/s 2.9s\n",
            "                   all        279        292      0.948      0.942      0.974       0.82\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/30      5.83G     0.7038     0.3547    0.01811         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.5it/s 1:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.8it/s 3.2s\n",
            "                   all        279        292      0.979      0.949      0.987      0.784\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/30      5.86G     0.6374     0.3155     0.0162         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.5it/s 1:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.8it/s 3.2s\n",
            "                   all        279        292      0.968      0.949      0.977      0.815\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/30      5.92G     0.6003     0.3005    0.01509         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.5it/s 1:03\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.1it/s 2.9s\n",
            "                   all        279        292      0.982      0.951      0.985      0.855\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/30      5.94G     0.5945     0.2834    0.01508         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.5it/s 1:03\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.1it/s 2.9s\n",
            "                   all        279        292      0.976      0.958      0.985      0.859\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/30         6G     0.5491      0.281    0.01372         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.5it/s 1:03\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.4it/s 3.7s\n",
            "                   all        279        292      0.949      0.976      0.983       0.88\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/30      6.03G     0.5257     0.2693    0.01321         30        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.5it/s 1:03\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.2it/s 2.8s\n",
            "                   all        279        292      0.988      0.962      0.987      0.913\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/30      6.09G     0.5106     0.2707    0.01262         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.5it/s 1:02\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.1it/s 2.9s\n",
            "                   all        279        292       0.96      0.979      0.988      0.921\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/30      6.11G     0.5075     0.2592    0.01256         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.5it/s 1:03\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.1it/s 2.9s\n",
            "                   all        279        292      0.982       0.95      0.987      0.906\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/30      6.17G     0.4811     0.2569     0.0119         33        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.5it/s 1:03\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.6it/s 3.4s\n",
            "                   all        279        292      0.961      0.938      0.986      0.896\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/30       6.2G     0.4647     0.2366    0.01124         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.5it/s 1:03\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.2it/s 2.8s\n",
            "                   all        279        292      0.989      0.941      0.986      0.934\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/30      6.26G     0.4187       0.22    0.01016         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.5it/s 1:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.1it/s 2.9s\n",
            "                   all        279        292      0.986      0.978      0.992      0.917\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/30      6.28G      0.418      0.219    0.01012         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.4it/s 1:05\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.8it/s 3.2s\n",
            "                   all        279        292      0.982      0.979      0.991       0.92\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/30      6.34G     0.4101     0.2256   0.009898         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.4it/s 1:06\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.2it/s 2.8s\n",
            "                   all        279        292      0.989      0.983       0.99      0.913\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/30      6.37G      0.377     0.2077   0.008922         28        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.5it/s 1:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.6it/s 3.5s\n",
            "                   all        279        292      0.986      0.973      0.987      0.922\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/30      6.43G     0.3665     0.2092    0.00858         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.5it/s 1:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.1it/s 2.9s\n",
            "                   all        279        292      0.963      0.974      0.989       0.94\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/30      6.46G     0.4091     0.2211    0.01556         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.5it/s 1:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.2it/s 2.8s\n",
            "                   all        279        292      0.976      0.983      0.991      0.943\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/30      6.52G     0.3776     0.1688    0.01422         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.5it/s 1:02\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.8it/s 3.2s\n",
            "                   all        279        292      0.969      0.974      0.988      0.933\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/30      6.54G     0.3034     0.1551    0.01083         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.6it/s 1:01\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.4it/s 3.7s\n",
            "                   all        279        292      0.976      0.976      0.987      0.948\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/30       6.6G     0.2784     0.1407   0.009724         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.6it/s 1:01\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.2it/s 2.8s\n",
            "                   all        279        292      0.979      0.981      0.993      0.949\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/30      6.63G     0.2666      0.125   0.009394         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.6it/s 1:01\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.1it/s 2.9s\n",
            "                   all        279        292      0.973       0.97      0.991      0.953\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/30      6.69G     0.2411     0.1184   0.008282         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.6it/s 1:01\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.2it/s 2.8s\n",
            "                   all        279        292      0.986      0.975      0.992      0.954\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/30      6.71G     0.2274     0.1211   0.007691         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.6it/s 1:01\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.2it/s 2.8s\n",
            "                   all        279        292      0.979      0.979      0.992      0.958\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/30      6.77G     0.2149     0.1123   0.007225         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.6it/s 1:01\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.0it/s 3.0s\n",
            "                   all        279        292      0.984      0.976      0.992       0.96\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/30       6.8G     0.2181     0.1123   0.007285         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.6it/s 1:02\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.4it/s 3.8s\n",
            "                   all        279        292      0.976      0.966       0.99      0.957\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/30      6.86G     0.2084     0.1087   0.007009         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.5it/s 1:02\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.0it/s 3.0s\n",
            "                   all        279        292      0.975      0.973      0.991      0.962\n",
            "\n",
            "30 epochs completed in 0.566 hours.\n",
            "Optimizer stripped from /content/runs/detect/train/weights/last.pt, 20.3MB\n",
            "Optimizer stripped from /content/runs/detect/train/weights/best.pt, 20.3MB\n",
            "\n",
            "Validating /content/runs/detect/train/weights/best.pt...\n",
            "Ultralytics 8.4.9 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO26s summary (fused): 122 layers, 9,465,567 parameters, 0 gradients, 20.5 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.8it/s 5.0s\n",
            "                   all        279        292      0.976      0.967      0.991      0.962\n",
            "Speed: 0.3ms preprocess, 5.6ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/train\u001b[0m\n",
            "\n",
            "TEST EVAL: /content/runs/detect/train/weights/best.pt\n",
            "Ultralytics 8.4.9 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO26s summary (fused): 122 layers, 9,465,567 parameters, 0 gradients, 20.5 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2382.3Â±510.9 MB/s, size: 135.2 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/pizza_only_dataset/test/labels... 281 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 281/281 2.4Kit/s 0.1s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/pizza_only_dataset/test/labels.cache\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 1.4s/it 25.7s\n",
            "                   all        281        313      0.995      0.917      0.953      0.929\n",
            "Speed: 1.1ms preprocess, 88.1ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
            "\n",
            "==============================\n",
            "TRAIN (1-class pizza): yolo11s.pt\n",
            "==============================\n",
            "Ultralytics 8.4.9 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/pizza_only.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11s.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=train2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/train2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
            "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
            " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
            " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
            " 23        [16, 19, 22]  1    819795  ultralytics.nn.modules.head.Detect           [1, 16, None, [128, 256, 512]]\n",
            "YOLO11s summary: 182 layers, 9,428,179 parameters, 9,428,163 gradients, 21.5 GFLOPs\n",
            "\n",
            "Transferred 493/499 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2740.6Â±621.6 MB/s, size: 170.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/pizza_only_dataset/train/labels.cache... 2522 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2522/2522 813.7Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 478.6Â±256.5 MB/s, size: 186.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/pizza_only_dataset/val/labels.cache... 279 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 279/279 12.6Mit/s 0.0s\n",
            "Plotting labels to /content/runs/detect/train2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/train2\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/30      4.64G       0.65      1.032      1.295         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.6it/s 1:01\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.9it/s 3.1s\n",
            "                   all        279        292      0.169      0.315     0.0807     0.0286\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/30      5.43G     0.6807     0.5469      1.304         30        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.8it/s 55.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.0it/s 4.6s\n",
            "                   all        279        292      0.607      0.432      0.528      0.338\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/30      5.43G     0.6667     0.5164      1.291         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.9it/s 54.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.4it/s 3.8s\n",
            "                   all        279        292      0.541      0.445      0.469       0.27\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/30      5.43G     0.6098     0.4846      1.248         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.9it/s 54.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.3it/s 3.9s\n",
            "                   all        279        292      0.864      0.808      0.876      0.654\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/30      5.43G     0.5677     0.4327      1.212         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.9it/s 54.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.0it/s 4.5s\n",
            "                   all        279        292      0.972      0.818      0.908      0.701\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/30      5.43G      0.568     0.4331       1.21         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.9it/s 53.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.6it/s 3.4s\n",
            "                   all        279        292      0.953      0.895      0.942      0.796\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/30      5.43G     0.5169     0.3945      1.177         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.9it/s 54.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.6it/s 3.5s\n",
            "                   all        279        292      0.979      0.955      0.973       0.85\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/30      5.43G     0.4915     0.3755       1.15         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.9it/s 53.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.9it/s 4.8s\n",
            "                   all        279        292       0.82      0.828      0.898      0.603\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/30      5.43G      0.466     0.3629      1.133         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 3.0it/s 53.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.7it/s 3.4s\n",
            "                   all        279        292      0.987      0.935      0.977      0.855\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/30      5.43G     0.4535     0.3497      1.122         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.9it/s 54.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.1it/s 4.3s\n",
            "                   all        279        292      0.982      0.952      0.981      0.882\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/30      5.43G     0.4387     0.3362      1.115         30        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.9it/s 54.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.1it/s 4.3s\n",
            "                   all        279        292      0.953      0.964      0.979      0.885\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/30      5.43G     0.4251     0.3345      1.105         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.9it/s 54.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.4it/s 3.7s\n",
            "                   all        279        292      0.983      0.971      0.989      0.861\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/30      5.43G     0.4182     0.3231      1.097         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.8it/s 55.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.5it/s 3.6s\n",
            "                   all        279        292      0.976       0.96      0.987       0.89\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/30      5.43G      0.399     0.3152      1.088         33        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.9it/s 55.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.0it/s 4.5s\n",
            "                   all        279        292      0.985      0.973      0.987      0.906\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/30      5.43G     0.3929     0.3036       1.08         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.9it/s 54.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.8it/s 3.2s\n",
            "                   all        279        292      0.946      0.973      0.984      0.899\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/30      5.43G     0.3692     0.2911      1.063         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.9it/s 54.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.4it/s 3.8s\n",
            "                   all        279        292      0.986      0.972      0.988      0.908\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/30      5.43G     0.3681     0.2918      1.064         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.9it/s 53.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.3it/s 4.0s\n",
            "                   all        279        292      0.996      0.968      0.986       0.91\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/30      5.43G     0.3707     0.2873      1.064         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.9it/s 53.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.4it/s 3.7s\n",
            "                   all        279        292      0.985      0.973      0.985      0.906\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/30      5.43G     0.3543     0.2762      1.053         28        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.9it/s 55.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.3it/s 3.9s\n",
            "                   all        279        292      0.985      0.962      0.985      0.906\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/30      5.43G     0.3387     0.2771      1.038         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.9it/s 54.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.9it/s 4.7s\n",
            "                   all        279        292      0.989      0.973      0.986      0.936\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/30      5.43G     0.2919     0.2287      1.082         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.8it/s 55.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.3it/s 3.9s\n",
            "                   all        279        292      0.975      0.952      0.986      0.906\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/30      5.43G     0.2845     0.2205      1.069         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 3.0it/s 53.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.0it/s 3.0s\n",
            "                   all        279        292      0.993      0.959      0.989      0.916\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/30      5.43G      0.266     0.2055      1.043         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 3.0it/s 53.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.6it/s 3.5s\n",
            "                   all        279        292      0.986      0.965      0.989      0.933\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/30      5.43G     0.2443      0.192      1.026         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 3.0it/s 53.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.2it/s 2.8s\n",
            "                   all        279        292      0.982      0.976      0.989      0.935\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/30      5.43G     0.2382     0.1821      1.024         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 3.0it/s 53.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.5it/s 3.6s\n",
            "                   all        279        292      0.986      0.965      0.989      0.932\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/30      5.43G     0.2256     0.1727      1.007         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 3.0it/s 53.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.0it/s 3.0s\n",
            "                   all        279        292      0.989      0.966      0.991      0.946\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/30      5.43G     0.2238     0.1675      1.008         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 3.0it/s 53.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.5it/s 3.6s\n",
            "                   all        279        292      0.979      0.961      0.989      0.938\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/30      5.43G     0.2181     0.1621     0.9972         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 3.0it/s 52.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.6it/s 3.4s\n",
            "                   all        279        292       0.99      0.973       0.99      0.949\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/30      5.43G     0.2083     0.1566      1.003         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 3.0it/s 52.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.3it/s 3.8s\n",
            "                   all        279        292      0.982      0.979       0.99      0.948\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/30      5.43G      0.198     0.1559     0.9904         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 3.0it/s 53.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.1it/s 2.9s\n",
            "                   all        279        292       0.98      0.982      0.992      0.944\n",
            "\n",
            "30 epochs completed in 0.490 hours.\n",
            "Optimizer stripped from /content/runs/detect/train2/weights/last.pt, 19.2MB\n",
            "Optimizer stripped from /content/runs/detect/train2/weights/best.pt, 19.2MB\n",
            "\n",
            "Validating /content/runs/detect/train2/weights/best.pt...\n",
            "Ultralytics 8.4.9 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11s summary (fused): 101 layers, 9,413,187 parameters, 0 gradients, 21.3 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.7it/s 5.2s\n",
            "                   all        279        292      0.991      0.973       0.99      0.949\n",
            "Speed: 0.3ms preprocess, 4.6ms inference, 0.0ms loss, 6.3ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/train2\u001b[0m\n",
            "\n",
            "TEST EVAL: /content/runs/detect/train2/weights/best.pt\n",
            "Ultralytics 8.4.9 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11s summary (fused): 101 layers, 9,413,187 parameters, 0 gradients, 21.3 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2163.7Â±1363.5 MB/s, size: 154.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/pizza_only_dataset/test/labels.cache... 281 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 281/281 107.1Mit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 5.7it/s 3.2s\n",
            "                   all        281        313      0.969      0.927      0.951      0.911\n",
            "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
            "\n",
            "==============================\n",
            "TRAIN (1-class pizza): yolov8s.pt\n",
            "==============================\n",
            "Ultralytics 8.4.9 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/pizza_only.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=train3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/train3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, 16, None, [128, 256, 512]]\n",
            "Model summary: 130 layers, 11,135,987 parameters, 11,135,971 gradients, 28.6 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2769.5Â±536.3 MB/s, size: 170.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/pizza_only_dataset/train/labels.cache... 2522 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2522/2522 881.5Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.4Â±0.9 ms, read: 1159.3Â±828.0 MB/s, size: 186.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/pizza_only_dataset/val/labels.cache... 279 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 279/279 10.4Mit/s 0.0s\n",
            "Plotting labels to /content/runs/detect/train3/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/train3\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/30      3.74G     0.6174     0.7773      1.261         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.7it/s 58.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.3it/s 4.0s\n",
            "                   all        279        292      0.295      0.411      0.231     0.0979\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/30      4.86G     0.6239     0.5136      1.253         30        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.9it/s 55.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.7it/s 3.3s\n",
            "                   all        279        292      0.748      0.741      0.793      0.519\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/30      4.86G      0.606     0.4821      1.237         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.9it/s 53.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.1it/s 4.4s\n",
            "                   all        279        292      0.854      0.881      0.913       0.68\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/30      4.86G     0.5594     0.4515      1.203         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 3.0it/s 52.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.7it/s 3.3s\n",
            "                   all        279        292      0.987      0.921      0.964       0.82\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/30      4.86G     0.5294     0.4153      1.177         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.9it/s 53.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.0it/s 4.4s\n",
            "                   all        279        292      0.919       0.93      0.962       0.78\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/30      4.86G     0.5127       0.41      1.168         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 3.0it/s 53.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.4it/s 3.7s\n",
            "                   all        279        292      0.962      0.943      0.981      0.858\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/30      4.86G     0.4781       0.38      1.138         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.9it/s 54.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.2it/s 4.0s\n",
            "                   all        279        292      0.964      0.928      0.977      0.835\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/30      4.86G     0.4563     0.3588      1.115         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 3.0it/s 53.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.0it/s 4.5s\n",
            "                   all        279        292      0.982      0.959      0.983      0.877\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/30      4.86G      0.428     0.3414      1.097         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 3.0it/s 52.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.5it/s 3.7s\n",
            "                   all        279        292      0.982      0.966      0.984      0.893\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/30      4.86G     0.4088     0.3328      1.088         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.9it/s 54.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.1it/s 4.4s\n",
            "                   all        279        292      0.975      0.966      0.985      0.904\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/30      4.86G      0.396     0.3151      1.077         30        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.9it/s 53.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.2it/s 4.1s\n",
            "                   all        279        292      0.969      0.973      0.988      0.916\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/30      4.86G     0.3942     0.3179      1.075         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.9it/s 53.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.2it/s 4.1s\n",
            "                   all        279        292      0.983      0.976      0.992        0.9\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/30      4.86G     0.3801     0.3071      1.067         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.9it/s 54.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.2it/s 4.1s\n",
            "                   all        279        292      0.983      0.959      0.986      0.913\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/30      4.86G     0.3647     0.3017       1.06         33        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.9it/s 54.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.1it/s 4.4s\n",
            "                   all        279        292      0.977      0.969      0.984      0.914\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/30      4.86G     0.3627     0.2917      1.055         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.9it/s 54.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.4it/s 3.7s\n",
            "                   all        279        292      0.985      0.966      0.985       0.91\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/30      4.86G     0.3462     0.2811      1.044         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.9it/s 54.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.2it/s 4.1s\n",
            "                   all        279        292      0.985      0.966      0.987       0.93\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/30      4.86G     0.3361     0.2755      1.041         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 3.0it/s 53.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.4it/s 3.8s\n",
            "                   all        279        292      0.983      0.969      0.989      0.932\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/30      4.86G     0.3337     0.2703      1.035         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.9it/s 54.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.3it/s 3.9s\n",
            "                   all        279        292      0.989      0.953       0.99      0.937\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/30      4.86G     0.3193     0.2608      1.026         28        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.9it/s 53.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.1it/s 4.3s\n",
            "                   all        279        292      0.979      0.957      0.985      0.916\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/30      4.86G     0.3075     0.2578      1.013         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 3.0it/s 53.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.5it/s 3.7s\n",
            "                   all        279        292      0.979      0.975      0.986      0.938\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/30      4.86G     0.2645     0.2144      1.051         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 2.9it/s 53.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.1it/s 4.2s\n",
            "                   all        279        292      0.993      0.975      0.988      0.938\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/30      4.86G     0.2504     0.1932       1.03         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 3.0it/s 51.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.7it/s 3.3s\n",
            "                   all        279        292       0.99      0.969      0.993       0.94\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/30      4.86G     0.2431     0.1852      1.015         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 3.1it/s 51.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.2it/s 4.1s\n",
            "                   all        279        292      0.983      0.974      0.991      0.936\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/30      4.86G     0.2268     0.1762      1.004         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 3.1it/s 50.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.3it/s 3.8s\n",
            "                   all        279        292      0.963      0.981       0.99      0.944\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/30      4.86G     0.2226     0.1708      1.008         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 3.1it/s 51.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.5it/s 3.6s\n",
            "                   all        279        292      0.989      0.973      0.991      0.945\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/30      4.86G     0.2043     0.1623     0.9862         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 3.1it/s 51.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.1it/s 4.4s\n",
            "                   all        279        292       0.97      0.986      0.988      0.951\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/30      4.86G     0.2088     0.1602     0.9897         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 3.0it/s 52.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.6it/s 3.5s\n",
            "                   all        279        292       0.99      0.973      0.992       0.95\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/30      4.86G     0.1927     0.1518     0.9675         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 3.0it/s 52.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.0it/s 4.4s\n",
            "                   all        279        292      0.989      0.973      0.991      0.949\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/30      4.86G      0.187     0.1454     0.9766         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 3.1it/s 51.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.4it/s 3.8s\n",
            "                   all        279        292      0.994      0.966      0.992      0.952\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/30      4.86G     0.1761     0.1434     0.9675         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 158/158 3.0it/s 52.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.1it/s 4.3s\n",
            "                   all        279        292      0.986       0.97      0.992      0.949\n",
            "\n",
            "30 epochs completed in 0.485 hours.\n",
            "Optimizer stripped from /content/runs/detect/train3/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from /content/runs/detect/train3/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating /content/runs/detect/train3/weights/best.pt...\n",
            "Ultralytics 8.4.9 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 73 layers, 11,125,971 parameters, 0 gradients, 28.4 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.0it/s 4.4s\n",
            "                   all        279        292      0.994      0.966      0.992      0.952\n",
            "Speed: 0.3ms preprocess, 4.2ms inference, 0.0ms loss, 4.7ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/train3\u001b[0m\n",
            "\n",
            "TEST EVAL: /content/runs/detect/train3/weights/best.pt\n",
            "Ultralytics 8.4.9 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 73 layers, 11,125,971 parameters, 0 gradients, 28.4 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2400.8Â±978.6 MB/s, size: 154.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/pizza_only_dataset/test/labels.cache... 281 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 281/281 73.7Mit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 4.2it/s 4.3s\n",
            "                   all        281        313      0.983      0.927      0.955      0.917\n",
            "Speed: 1.6ms preprocess, 7.6ms inference, 0.0ms loss, 1.9ms postprocess per image\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   base_model                                 best_weights  precision  \\\n",
              "0  yolo26s.pt   /content/runs/detect/train/weights/best.pt   0.995441   \n",
              "1  yolo11s.pt  /content/runs/detect/train2/weights/best.pt   0.969180   \n",
              "2  yolov8s.pt  /content/runs/detect/train3/weights/best.pt   0.983059   \n",
              "\n",
              "     recall      ap50    ap5095  inf_ms/img     fps_est  \n",
              "0  0.916933  0.953185  0.928797   88.062839   11.355528  \n",
              "1  0.926518  0.950701  0.910976    5.996221  166.771718  \n",
              "2  0.926986  0.955433  0.917276    7.625015  131.147279  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0ed9606b-94a9-4db3-8eaf-bdca205953ea\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>base_model</th>\n",
              "      <th>best_weights</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>ap50</th>\n",
              "      <th>ap5095</th>\n",
              "      <th>inf_ms/img</th>\n",
              "      <th>fps_est</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>yolo26s.pt</td>\n",
              "      <td>/content/runs/detect/train/weights/best.pt</td>\n",
              "      <td>0.995441</td>\n",
              "      <td>0.916933</td>\n",
              "      <td>0.953185</td>\n",
              "      <td>0.928797</td>\n",
              "      <td>88.062839</td>\n",
              "      <td>11.355528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>yolo11s.pt</td>\n",
              "      <td>/content/runs/detect/train2/weights/best.pt</td>\n",
              "      <td>0.969180</td>\n",
              "      <td>0.926518</td>\n",
              "      <td>0.950701</td>\n",
              "      <td>0.910976</td>\n",
              "      <td>5.996221</td>\n",
              "      <td>166.771718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>yolov8s.pt</td>\n",
              "      <td>/content/runs/detect/train3/weights/best.pt</td>\n",
              "      <td>0.983059</td>\n",
              "      <td>0.926986</td>\n",
              "      <td>0.955433</td>\n",
              "      <td>0.917276</td>\n",
              "      <td>7.625015</td>\n",
              "      <td>131.147279</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ed9606b-94a9-4db3-8eaf-bdca205953ea')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0ed9606b-94a9-4db3-8eaf-bdca205953ea button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0ed9606b-94a9-4db3-8eaf-bdca205953ea');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"base_model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"yolo26s.pt\",\n          \"yolo11s.pt\",\n          \"yolov8s.pt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"best_weights\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"/content/runs/detect/train/weights/best.pt\",\n          \"/content/runs/detect/train2/weights/best.pt\",\n          \"/content/runs/detect/train3/weights/best.pt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.013137778136659235,\n        \"min\": 0.9691799093679235,\n        \"max\": 0.995441240353974,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.995441240353974,\n          0.9691799093679235,\n          0.9830592498472243\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005673888268659797,\n        \"min\": 0.9169329073482428,\n        \"max\": 0.9269863876419314,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9169329073482428,\n          0.9265175718849841,\n          0.9269863876419314\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ap50\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0023670991691699876,\n        \"min\": 0.9507010769990022,\n        \"max\": 0.9554333049460758,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.953185467862747,\n          0.9507010769990022,\n          0.9554333049460758\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ap5095\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009036857456467668,\n        \"min\": 0.9109759427502858,\n        \"max\": 0.9287965344691222,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9287965344691222,\n          0.9109759427502858,\n          0.917275824627507\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"inf_ms/img\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 46.91806024503048,\n        \"min\": 5.996220537370429,\n        \"max\": 88.06283878292079,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          88.06283878292079,\n          5.996220537370429,\n          7.625015213533616\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fps_est\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 81.41801253706748,\n        \"min\": 11.35552764163155,\n        \"max\": 166.77171791258667,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          11.35552764163155,\n          166.77171791258667,\n          131.14727931625671\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_scored = df.copy()\n",
        "\n",
        "df_scored[\"precision_n\"] = normalize_series(df_scored[\"precision\"])\n",
        "df_scored[\"recall_n\"]    = normalize_series(df_scored[\"recall\"])\n",
        "df_scored[\"ap50_n\"]      = normalize_series(df_scored[\"ap50\"])\n",
        "df_scored[\"fps_n\"]       = normalize_series(df_scored[\"fps_est\"])\n",
        "\n",
        "df_scored[\"score\"] = (\n",
        "    WEIGHTS[\"recall\"]    * df_scored[\"recall_n\"] +\n",
        "    WEIGHTS[\"precision\"] * df_scored[\"precision_n\"] +\n",
        "    WEIGHTS[\"ap50\"]      * df_scored[\"ap50_n\"] +\n",
        "    WEIGHTS[\"fps\"]       * df_scored[\"fps_n\"]\n",
        ")\n",
        "\n",
        "cols = [\"base_model\",\"score\",\"recall\",\"precision\",\"ap50\",\"ap5095\",\"inf_ms/img\",\"fps_est\",\"best_weights\"]\n",
        "df_ranked = df_scored.sort_values(\"score\", ascending=False).reset_index(drop=True)\n",
        "df_ranked[cols]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "ytV9XwCgaO_7",
        "outputId": "905d338b-19b0-4f25-d6b9-f9362cecfd51"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   base_model     score    recall  precision      ap50    ap5095  inf_ms/img  \\\n",
              "0  yolov8s.pt  0.859858  0.926986   0.983059  0.955433  0.917276    7.625015   \n",
              "1  yolo11s.pt  0.533679  0.926518   0.969180  0.950701  0.910976    5.996221   \n",
              "2  yolo26s.pt  0.331248  0.916933   0.995441  0.953185  0.928797   88.062839   \n",
              "\n",
              "      fps_est                                 best_weights  \n",
              "0  131.147279  /content/runs/detect/train3/weights/best.pt  \n",
              "1  166.771718  /content/runs/detect/train2/weights/best.pt  \n",
              "2   11.355528   /content/runs/detect/train/weights/best.pt  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-29fefa4f-9098-4d90-8073-1969725b5557\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>base_model</th>\n",
              "      <th>score</th>\n",
              "      <th>recall</th>\n",
              "      <th>precision</th>\n",
              "      <th>ap50</th>\n",
              "      <th>ap5095</th>\n",
              "      <th>inf_ms/img</th>\n",
              "      <th>fps_est</th>\n",
              "      <th>best_weights</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>yolov8s.pt</td>\n",
              "      <td>0.859858</td>\n",
              "      <td>0.926986</td>\n",
              "      <td>0.983059</td>\n",
              "      <td>0.955433</td>\n",
              "      <td>0.917276</td>\n",
              "      <td>7.625015</td>\n",
              "      <td>131.147279</td>\n",
              "      <td>/content/runs/detect/train3/weights/best.pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>yolo11s.pt</td>\n",
              "      <td>0.533679</td>\n",
              "      <td>0.926518</td>\n",
              "      <td>0.969180</td>\n",
              "      <td>0.950701</td>\n",
              "      <td>0.910976</td>\n",
              "      <td>5.996221</td>\n",
              "      <td>166.771718</td>\n",
              "      <td>/content/runs/detect/train2/weights/best.pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>yolo26s.pt</td>\n",
              "      <td>0.331248</td>\n",
              "      <td>0.916933</td>\n",
              "      <td>0.995441</td>\n",
              "      <td>0.953185</td>\n",
              "      <td>0.928797</td>\n",
              "      <td>88.062839</td>\n",
              "      <td>11.355528</td>\n",
              "      <td>/content/runs/detect/train/weights/best.pt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29fefa4f-9098-4d90-8073-1969725b5557')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-29fefa4f-9098-4d90-8073-1969725b5557 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-29fefa4f-9098-4d90-8073-1969725b5557');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_ranked[cols]\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"base_model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"yolov8s.pt\",\n          \"yolo11s.pt\",\n          \"yolo26s.pt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.26670789848408505,\n        \"min\": 0.33124847807052427,\n        \"max\": 0.8598578070863495,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.8598578070863495,\n          0.533678735110807,\n          0.33124847807052427\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005673888268659796,\n        \"min\": 0.9169329073482428,\n        \"max\": 0.9269863876419314,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9269863876419314,\n          0.9265175718849841,\n          0.9169329073482428\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.013137778136659235,\n        \"min\": 0.9691799093679235,\n        \"max\": 0.995441240353974,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9830592498472243,\n          0.9691799093679235,\n          0.995441240353974\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ap50\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.002367099169169988,\n        \"min\": 0.9507010769990022,\n        \"max\": 0.9554333049460758,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9554333049460758,\n          0.9507010769990022,\n          0.953185467862747\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ap5095\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00903685745646767,\n        \"min\": 0.9109759427502858,\n        \"max\": 0.9287965344691222,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.917275824627507,\n          0.9109759427502858,\n          0.9287965344691222\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"inf_ms/img\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 46.91806024503048,\n        \"min\": 5.996220537370429,\n        \"max\": 88.06283878292079,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          7.625015213533616,\n          5.996220537370429,\n          88.06283878292079\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fps_est\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 81.41801253706748,\n        \"min\": 11.35552764163155,\n        \"max\": 166.77171791258667,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          131.14727931625671,\n          166.77171791258667,\n          11.35552764163155\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"best_weights\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"/content/runs/detect/train3/weights/best.pt\",\n          \"/content/runs/detect/train2/weights/best.pt\",\n          \"/content/runs/detect/train/weights/best.pt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "YOLOv8s Ğ¿Ñ€Ğ¾Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ»Ğ° Ğ½Ğ°Ğ¸Ğ»ÑƒÑ‡ÑˆĞ¸Ğ¹ Ğ±Ğ°Ğ»Ğ°Ğ½Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº:\n",
        "\n",
        "Recall â‰ˆ 0.93 â€” Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ñ‡Ğ¸ÑĞ»Ğ¾ Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ¾Ğ², Ñ‡Ñ‚Ğ¾ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ğ¾ Ğ´Ğ»Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ¿Ğ¾Ğ´ÑÑ‡Ñ‘Ñ‚Ğ°;\n",
        "\n",
        "Precision â‰ˆ 0.98 â€” Ğ½Ğ¸Ğ·ĞºĞ¾Ğµ Ñ‡Ğ¸ÑĞ»Ğ¾ Ğ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… ÑÑ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ğ¹;\n",
        "\n",
        "mAP@0.5 â‰ˆ 0.96 â€” Ğ²Ñ‹ÑĞ¾ĞºĞ°Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ»Ğ¾ĞºĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ².\n",
        "\n",
        "YOLO11s Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ° ÑĞ¾Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²Ğ¸Ğ¼Ğ¾Ğµ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾, Ğ¾Ğ´Ğ½Ğ°ĞºĞ¾ Ğ½ĞµĞ¼Ğ½Ğ¾Ğ³Ğ¾ ÑƒÑÑ‚ÑƒĞ¿Ğ°ĞµÑ‚ YOLOv8s Ğ¿Ğ¾ precision Ğ¸ mAP.\n",
        "\n",
        "YOLO26s Ğ¸Ğ¼ĞµĞµÑ‚ Ğ²Ñ‹ÑĞ¾ĞºĞ¸Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ precision Ğ¸ mAP, Ğ¾Ğ´Ğ½Ğ°ĞºĞ¾ ĞµÑ‘ Ğ²Ñ‹Ğ¸Ğ³Ñ€Ñ‹Ñˆ Ğ¿Ğ¾ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ñƒ Ğ½Ğµ ĞºĞ¾Ğ¼Ğ¿ĞµĞ½ÑĞ¸Ñ€ÑƒĞµÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸."
      ],
      "metadata": {
        "id": "Zzwtqixkxciu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "from pathlib import Path\n",
        "\n",
        "BEST_PT = Path(\"/content/runs/detect/train3/weights/best.pt\").resolve()\n",
        "assert BEST_PT.exists(), f\"Model not found: {BEST_PT}\"\n",
        "\n",
        "model = YOLO(str(BEST_PT))\n",
        "\n",
        "onnx_path = model.export(\n",
        "    format=\"onnx\",\n",
        "    imgsz=640,\n",
        "    opset=17,\n",
        "    simplify=True,\n",
        "    dynamic=False\n",
        ")\n",
        "\n",
        "print(\"ONNX model saved to:\", onnx_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anTIKcMtxRvV",
        "outputId": "53708414-ea88-489a-ab08-4d02225182d4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.4.9 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CPU (Intel Xeon CPU @ 2.00GHz)\n",
            "ğŸ’¡ ProTip: Export to OpenVINO format for best performance on Intel hardware. Learn more at https://docs.ultralytics.com/integrations/openvino/\n",
            "Model summary (fused): 73 layers, 11,125,971 parameters, 0 gradients, 28.4 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/runs/detect/train3/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (21.5 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx>=1.12.0,<2.0.0', 'onnxslim>=0.1.71', 'onnxruntime-gpu'] not found, attempting AutoUpdate...\n",
            "Using Python 3.12.12 environment at: /usr\n",
            "Resolved 14 packages in 258ms\n",
            "Prepared 6 packages in 6.12s\n",
            "Installed 6 packages in 290ms\n",
            " + colorama==0.4.6\n",
            " + coloredlogs==15.0.1\n",
            " + humanfriendly==10.0\n",
            " + onnx==1.20.1\n",
            " + onnxruntime-gpu==1.23.2\n",
            " + onnxslim==0.1.82\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 7.3s\n",
            "WARNING âš ï¸ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.20.1 opset 17...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.82...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 9.4s, saved as '/content/runs/detect/train3/weights/best.onnx' (42.7 MB)\n",
            "\n",
            "Export complete (10.6s)\n",
            "Results saved to \u001b[1m/content/runs/detect/train3/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=/content/runs/detect/train3/weights/best.onnx imgsz=640 \n",
            "Validate:        yolo val task=detect model=/content/runs/detect/train3/weights/best.onnx imgsz=640 data=/content/pizza_only.yaml  \n",
            "Visualize:       https://netron.app\n",
            "ONNX model saved to: /content/runs/detect/train3/weights/best.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.predict(\"pizzsd.PNG\", conf=0.25, verbose=False)\n",
        "\n",
        "for box in results[0].boxes:\n",
        "    print(int(box.cls.item()), box.conf.item())"
      ],
      "metadata": {
        "id": "8z2_oWzR0p9U"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}